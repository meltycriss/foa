{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_foa\n",
    "from gym import wrappers\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import copy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-11 13:52:21,410] Making new env: foa-v0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "ENV_NAME = 'foa-v0'\n",
    "env = gym.make(ENV_NAME)\n",
    "RECORD = False\n",
    "\n",
    "if RECORD:\n",
    "    env = wrappers.Monitor(env, 'capa1w', force=True, video_callable=lambda episode_id: True)\n",
    "TAU = .01\n",
    "GAMMA = .9\n",
    "LR_actor = .001\n",
    "LR_critic = .001\n",
    "EXPERIENCE_CAPACITY = 7500\n",
    "TARGET_UPDATE_FREQUENCY = 200\n",
    "MAX_EPI = 2*int(1e4)\n",
    "MAX_STEP = 100\n",
    "BATCH_SIZE = 32\n",
    "#EPSILON = .1\n",
    "N_STATES = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.shape[0]\n",
    "N_UAVS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classes\n",
    "class Experience(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.mem = []\n",
    "        self.pos = 0\n",
    "    \n",
    "    def push(self, o, a, r, o_next):\n",
    "        if len(self.mem) < self.capacity:\n",
    "            self.mem.append(None)\n",
    "        self.mem[self.pos] = Transition(o, a, r, o_next)\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, size):\n",
    "        return random.sample(self.mem, min(size, len(self.mem)))\n",
    "        #return self.mem[:1]\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fcS = nn.Linear(N_STATES, 150)\n",
    "        self.fcS.weight.data.normal_(0, 0.1)\n",
    "        self.fcA = nn.Linear(N_ACTIONS, 150)\n",
    "        self.fcA.weight.data.normal_(0, 0.1)\n",
    "        self.fc1 = nn.Linear(150, 100)\n",
    "        self.fc1.weight.data.normal_(0, 0.1)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc2.weight.data.normal_(0, 0.1)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "        self.fc3.weight.data.normal_(0, 0.1)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        s = self.fcS(x)\n",
    "        a = self.fcA(y)\n",
    "        o = F.relu(s+a)\n",
    "        o = self.fc1(o)\n",
    "        o = F.relu(o)\n",
    "        o = self.fc2(o)\n",
    "        o = F.relu(o)\n",
    "        o = self.fc3(o)\n",
    "        return o\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES/N_UAVS, 150)\n",
    "        self.fc1.weight.data.normal_(0, 0.1)\n",
    "        self.fc2 = nn.Linear(150, 100)\n",
    "        self.fc2.weight.data.normal_(0, 0.1)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc3.weight.data.normal_(0, 0.1)\n",
    "        self.fc4 = nn.Linear(100, N_ACTIONS/N_UAVS)\n",
    "        self.fc4.weight.data.normal_(0, 0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_action(state, actor):\n",
    "    a = actor(Variable(Tensor(state).unsqueeze(0))).data.cpu().numpy()[0].astype('float64')\n",
    "    return a\n",
    "\n",
    "def update_actor_critic(target_actor, target_critic, \\\n",
    "                       actor, critic, exp, optim_actor, optim_critic):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sample minibatch\n",
    "    minibatch = Transition(*zip(*exp.sample(BATCH_SIZE)))\n",
    "    bat_o = Variable(Tensor(minibatch.state))\n",
    "    bat_a = Variable(Tensor(minibatch.action))\n",
    "    bat_r = Variable(Tensor(minibatch.reward)).unsqueeze(1)\n",
    "    bat_o_ = Variable(Tensor(minibatch.next_state))\n",
    "    \n",
    "    bat_a0_ = target_actor(bat_o_[:,:N_STATES/N_UAVS])\n",
    "    #bat_a1_ = target_actor(bat_o_[:,N_STATES/N_UAVS:-N_STATES/N_UAVS])\n",
    "    #bat_a2_ = target_actor(bat_o_[:,-N_STATES/N_UAVS:])\n",
    "    #bat_a_o_ = torch.cat([bat_a0_, bat_a1_, bat_a2_], dim=1)\n",
    "    bat_a_o_ = bat_a0_\n",
    "\n",
    "    Gt = bat_r + GAMMA * target_critic(bat_o_, bat_a_o_)\n",
    "    Gt.detach_()\n",
    "    eval_o = critic(bat_o, bat_a)\n",
    "    criterion = nn.MSELoss()\n",
    "    if use_cuda:\n",
    "        criterion.cuda()\n",
    "    loss = criterion(eval_o, Gt)\n",
    "    #optimizer = optim.Adam(critic.parameters(), lr=LR_critic)\n",
    "    optim_critic.zero_grad()\n",
    "    loss.backward()\n",
    "    optim_critic.step()\n",
    "    \n",
    "    # update actor\n",
    "    bat_a0 = actor(bat_o[:,:N_STATES/N_UAVS])\n",
    "    #bat_a1 = actor(bat_o[:,N_STATES/N_UAVS:-N_STATES/N_UAVS])\n",
    "    #bat_a2 = actor(bat_o[:,-N_STATES/N_UAVS:])\n",
    "    #bat_a_o = torch.cat([bat_a0, bat_a1, bat_a2], dim=1)\n",
    "    bat_a_o = bat_a0\n",
    "    \n",
    "    obj = torch.mean(critic(bat_o, bat_a_o))\n",
    "    #optimizer = optim.Adam(actor.parameters(), lr=-LR_actor)\n",
    "    optim_actor.zero_grad()\n",
    "    obj.backward()\n",
    "    optim_actor.step()    \n",
    "\n",
    "def update_target(target_actor, target_critic, \\\n",
    "                         actor, critic):\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    target_critic.load_state_dict(critic.state_dict())\n",
    "\n",
    "def soft_update(target, behavior, tau):\n",
    "    for key in target.state_dict().keys():\n",
    "        target.state_dict()[key].copy_(tau * behavior.state_dict()[key] + (1-tau) * target.state_dict()[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:0, epi:0\n",
      "n:0, epi:2000\n",
      "n:0, epi:4000\n",
      "n:0, epi:6000\n",
      "n:0, epi:8000\n",
      "n:0, epi:10000\n",
      "n:0, epi:12000\n",
      "n:0, epi:14000\n",
      "n:0, epi:16000\n",
      "n:0, epi:18000\n",
      "--- 26.5061932643 minutes ---\n",
      "n:1, epi:0\n",
      "n:1, epi:2000\n",
      "n:1, epi:4000\n",
      "n:1, epi:6000\n",
      "n:1, epi:8000\n",
      "n:1, epi:10000\n",
      "n:1, epi:12000\n",
      "n:1, epi:14000\n",
      "n:1, epi:16000\n",
      "n:1, epi:18000\n",
      "--- 43.2512533665 minutes ---\n",
      "n:2, epi:0\n",
      "n:2, epi:2000\n",
      "n:2, epi:4000\n",
      "n:2, epi:6000\n",
      "n:2, epi:8000\n",
      "n:2, epi:10000\n",
      "n:2, epi:12000\n",
      "n:2, epi:14000\n",
      "n:2, epi:16000\n",
      "n:2, epi:18000\n",
      "--- 70.5654656688 minutes ---\n",
      "n:3, epi:0\n",
      "n:3, epi:2000\n",
      "n:3, epi:4000\n",
      "n:3, epi:6000\n",
      "n:3, epi:8000\n",
      "n:3, epi:10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_vec_r = []\n",
    "n_vec_avg_cost = []\n",
    "n_vec_total_cost = []\n",
    "n_vec_target_update = []\n",
    "n_vec_experience_refresh = []\n",
    "n_vec_training_time = []\n",
    "for n in xrange(5):    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    target_actor = Actor()\n",
    "    target_critic = Critic()\n",
    "    actor = Actor()\n",
    "    critic = Critic()\n",
    "    if use_cuda:\n",
    "        target_actor.cuda()\n",
    "        target_critic.cuda()\n",
    "        actor.cuda()\n",
    "        critic.cuda()\n",
    "    exp = Experience(EXPERIENCE_CAPACITY)\n",
    "    optim_critic = optim.Adam(critic.parameters(), lr=LR_critic)\n",
    "    optim_actor = optim.Adam(actor.parameters(), lr=-LR_actor)\n",
    "\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    target_critic.load_state_dict(critic.state_dict())\n",
    "    \n",
    "    vec_r = []\n",
    "    vec_avg_cost = []\n",
    "    vec_total_cost = []\n",
    "    vec_target_update = []\n",
    "    vec_experience_refresh = []\n",
    "    update_counter = 0\n",
    "    for epi in xrange(MAX_EPI):\n",
    "        if epi%(MAX_EPI/10)==0:\n",
    "            print 'n:{}, epi:{}'.format(n, epi)\n",
    "            \n",
    "        o = env.reset()\n",
    "        acc_r = 0\n",
    "        \n",
    "        local_r = []\n",
    "        \n",
    "        avg_cost = np.zeros([4])\n",
    "        total_cost = 0\n",
    "    \n",
    "        counter = 0\n",
    "        #for t in xrange(MAX_STEP):    \n",
    "        while True:\n",
    "            counter += 1\n",
    "            \n",
    "            if RECORD:\n",
    "                env.render()\n",
    "            \n",
    "            a0 = choose_action(o[:N_STATES/N_UAVS], actor)\n",
    "            #a1 = choose_action(o[N_STATES/N_UAVS:-N_STATES/N_UAVS], actor)\n",
    "            #a2 = choose_action(o[-N_STATES/N_UAVS:], actor)\n",
    "            #a = np.hstack([a0, a1, a2])\n",
    "            a = a0\n",
    "            \n",
    "            o_, r, done, info = env.step(a)\n",
    "            exp.push(o, a, r, o_)\n",
    "            \n",
    "            cost = np.array(info['cost'])\n",
    "            avg_cost += (cost-avg_cost)/(counter)\n",
    "            total_cost += r\n",
    "            \n",
    "            update_actor_critic(target_actor, target_critic, \\\n",
    "                               actor, critic, exp, optim_actor, optim_critic)\n",
    "            update_counter += 1\n",
    "            \n",
    "            if update_counter % TARGET_UPDATE_FREQUENCY == 0:\n",
    "                vec_target_update.append(epi)\n",
    "                update_target(target_actor, target_critic, \\\n",
    "                             actor, critic)\n",
    "            if update_counter % EXPERIENCE_CAPACITY == 0:\n",
    "                vec_experience_refresh.append(epi)\n",
    "            \n",
    "            local_r.append(r)\n",
    "            acc_r += r\n",
    "            o = o_\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        vec_r.append(acc_r)\n",
    "        vec_avg_cost.append(avg_cost)\n",
    "        vec_total_cost.append(total_cost)\n",
    "        \n",
    "    n_vec_r.append(vec_r)\n",
    "    n_vec_avg_cost.append(vec_avg_cost)\n",
    "    n_vec_total_cost.append(vec_total_cost)\n",
    "    n_vec_target_update.append(vec_target_update)\n",
    "    n_vec_experience_refresh.append(vec_experience_refresh)\n",
    "    n_vec_training_time.append((time.time() - start_time)/60)\n",
    "    \n",
    "    torch.save(actor.state_dict(), 'actor{}.pt'.format(n))\n",
    "    \n",
    "    print \"--- {} minutes ---\".format((time.time() - start_time)/60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_1d(vec, title=None, xlabel=None, ylabel=None, save=False, ylim=None, begin=0, marker='', target=None, exp=None):\n",
    "    record = np.array(vec)\n",
    "    if len(record.shape) is not 1:\n",
    "        print 'vec should be 1D array [e0, e1, ...]'\n",
    "        return\n",
    "    if ylim is not None:\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim(ylim)\n",
    "    mu = record.mean(axis=0)\n",
    "    plt.plot(np.array(range(record.shape[0]))+begin, record, marker)\n",
    "    plt.plot(np.array(range(record.shape[0]))+begin, mu*np.ones(record.shape[0]), color='red')\n",
    "    patches = []\n",
    "    if target is not None and len(target)>0:\n",
    "        target = np.array(target)\n",
    "        target_color = 'b'\n",
    "        target_patch = mpatches.Patch(color=target_color, label='update target')\n",
    "        patches.append(target_patch)\n",
    "        for t in target:\n",
    "            plt.axvline(t, ls='dashed', c=target_color)\n",
    "    if exp is not None and len(exp)>0:\n",
    "        exp = np.array(exp)\n",
    "        exp_color = 'r'\n",
    "        exp_patch = mpatches.Patch(color=exp_color, label='exp refresh')\n",
    "        patches.append(exp_patch)\n",
    "        for e in exp:\n",
    "            plt.axvline(e, ls='dashed', c=exp_color)\n",
    "    if len(patches)>0:\n",
    "        plt.legend(handles=patches)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel, rotation=45)\n",
    "    if save:\n",
    "        plt.savefig('{}.png'.format(title))      \n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_2d(vec, title=None, xlabel=None, ylabel=None, save=False, ylim=None, begin=0):\n",
    "    record = np.array(vec)\n",
    "    if len(record.shape) is not 2:\n",
    "        print 'vec should be 2D array [[seq0], [seq1], ...]'\n",
    "        return\n",
    "    if ylim is not None:\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim(ylim)\n",
    "    mu = record.mean(axis=0)\n",
    "    sigma = record.std(axis=0)\n",
    "    lower_bound = mu-sigma\n",
    "    upper_bound = mu+sigma\n",
    "    plt.plot(np.array(range(mu.shape[0]))+begin, mu, color='red')\n",
    "    plt.fill_between(np.array(range(mu.shape[0]))+begin, lower_bound, upper_bound, facecolor='blue', alpha=0.5)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel, rotation=45)\n",
    "    if save:\n",
    "        plt.savefig('{}.png'.format(title))\n",
    "    plt.show()\n",
    "\n",
    "# data\n",
    "n_vec_avg_cost = np.array(n_vec_avg_cost)\n",
    "n_vec_total_cost = np.array(n_vec_total_cost)\n",
    "n_vec_target_update = np.array(n_vec_target_update)\n",
    "n_vec_experience_refresh = np.array(n_vec_experience_refresh)\n",
    "\n",
    "\n",
    "cost = gym_foa.envs.FoaEnv.Cost(*np.rollaxis(n_vec_avg_cost,2))\n",
    "avg_cost = cost.collision[0]+cost.goal[0]+cost.formation[0]+cost.v_pref[0]\n",
    "\n",
    "# param\n",
    "save = True\n",
    "marker = '.'\n",
    "\n",
    "target = np.array([10,20,30])\n",
    "experience = np.array([15,25])\n",
    "\n",
    "plot_avg_2d(n_vec_total_cost, title='total cost', ylim=[-8000,1000], save=save)\n",
    "for i in xrange(n_vec_avg_cost.shape[0]):\n",
    "    plot_avg_1d(n_vec_total_cost[i], title='total cost of {} \\n training time: {} minutes'.format(i, n_vec_training_time[i]), ylim=[-8000,1000], save=save,)\n",
    "                #target=n_vec_target_update[i], )\n",
    "                #exp=n_vec_experience_refresh[i])\n",
    "\n",
    "\n",
    "\n",
    "# marker = ''\n",
    "# int0 = slice(0,500)\n",
    "# plot_avg_1d(n_vec_total_cost[0][int0], title='total cost: first drop', ylim=[-8000,1000], begin=int0.start, save=save, marker=marker)\n",
    "# plot_avg_1d(cost.v_pref[0][int0], title='v_pref: first drop', begin=int0.start, save=save, marker=marker)\n",
    "\n",
    "# marker = ''\n",
    "# int1 = slice(3000,3200)\n",
    "# plot_avg_1d(n_vec_total_cost[0][int1], title='total cost: second drop', ylim=[-8000,1000], begin=int1.start, save=save, marker=marker)\n",
    "# plot_avg_1d(cost.v_pref[0][int1], title='v_pref: second drop', begin=int1.start, save=save, marker=marker)\n",
    "\n",
    "# int2 = slice(7000,8000)\n",
    "# plot_avg_1d(n_vec_total_cost[0][int2], title='total cost: second drop', ylim=[-8000,1000], begin=int2.start, save=save, marker=marker)\n",
    "# plot_avg_1d(cost.v_pref[0][int2], title='v_pref: second drop', begin=int2.start, save=save, marker=marker)\n",
    "\n",
    "# int3 = slice(9600,10000)\n",
    "# plot_avg_1d(n_vec_total_cost[0][int3], title='total cost: third drop', ylim=[-8000,1000], begin=int3.start, save=save, marker=marker)\n",
    "# plot_avg_1d(cost.v_pref[0][int3], title='v_pref: third drop', begin=int3.start, save=save, marker=marker)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020631469999040877"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.save(actor.state_dict(), 'actor_3w.param')\n",
    "#torch.save(critic.state_dict(), 'critic.param')\n",
    "\n",
    "#from gym import wrappers\n",
    "\n",
    "#env = wrappers.Monitor(env, 'exp', force=True)\n",
    "\n",
    "\n",
    "actor = Actor()\n",
    "actor.load_state_dict(torch.load('actor3.pt'))\n",
    "#actor.cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "for n in xrange(10):\n",
    "    o = env.reset()\n",
    "    for t in xrange(MAX_STEP):\n",
    "        counter += 1\n",
    "#        print 'n:{}, t:{}'.format(n, t)\n",
    "#         env.render()\n",
    "        #a0 = choose_action(o[:N_STATES/N_UAVS], actor)\n",
    "        \n",
    "        \n",
    "        a0 = actor(Variable(torch.FloatTensor(o[:N_STATES/N_UAVS]).unsqueeze(0))).data.cpu().numpy()[0].astype('float64')\n",
    "        \n",
    "        \n",
    "        #a1 = choose_action(o[N_STATES/N_UAVS:-N_STATES/N_UAVS], actor)\n",
    "        #a2 = choose_action(o[-N_STATES/N_UAVS:], actor)\n",
    "        #a = np.hstack([a0, a1, a2])\n",
    "        \n",
    "#        print a0\n",
    "        \n",
    "        o_, r, done, info = env.step(a0)\n",
    "    \n",
    "        o = o_\n",
    "        if done:\n",
    "            break\n",
    "(time.time() - start_time)/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "name = 'capa_5k_epi_2w_x5'\n",
    "\n",
    "# Saving the objects:\n",
    "with open('{}_total_cost.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_total_cost, f)\n",
    "\n",
    "with open('{}_target_update.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_target_update, f)\n",
    "\n",
    "with open('{}_experience_refresh.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_experience_refresh, f)\n",
    "    \n",
    "    \n",
    "## Getting back the objects:\n",
    "#with open('objs.pickle') as f:  # Python 3: open(..., 'rb')\n",
    "#    k = pickle.load(f)\n",
    "    \n",
    "#print cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = np.array(range(10)).reshape(2,-1)\n",
    "s = slice(None,2)\n",
    "print s.step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
