{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_foa\n",
    "from gym import wrappers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "N = 1\n",
    "EXPERIENCE_CAPACITY = 7*int(1e3)\n",
    "MAX_EPI = 1*int(1e3)\n",
    "LR_actor = .001\n",
    "LR_critic = .001\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "exp_name = 'pendulum_version_alr_{}_clr_{}_bs_{}_capa_{}k_epi_{}k_x{}'.format(\\\n",
    "            LR_actor, LR_critic, BATCH_SIZE, float(EXPERIENCE_CAPACITY)/1000., float(MAX_EPI)/1000., N)\n",
    "exp_name = 'test'\n",
    "if os.path.exists(exp_name):\n",
    "    shutil.rmtree(exp_name)\n",
    "os.mkdir(exp_name)\n",
    "\n",
    "ENV_NAME = 'foa-v0'\n",
    "# test\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "env = gym.make(ENV_NAME)\n",
    "RECORD = True\n",
    "\n",
    "if RECORD:\n",
    "    #env = wrappers.Monitor(env, '{}/record'.format(exp_name), force=True, video_callable=lambda episode_id: True)\n",
    "    env = wrappers.Monitor(env, '{}/record'.format(exp_name), force=True)\n",
    "TAU = .01\n",
    "GAMMA = .99\n",
    "\n",
    "\n",
    "TARGET_UPDATE_FREQUENCY = 200\n",
    "\n",
    "MAX_STEP = 100\n",
    "\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 1./(1e5)\n",
    "N_STATES = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.shape[0]\n",
    "N_UAVS = 1\n",
    "V_MAX = env.action_space.high[0]\n",
    "print V_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uf_lb = -3.*(1e-3)\n",
    "uf_ub = 3.*(1e-3)\n",
    "\n",
    "def fanin_init(size, fanin=None):\n",
    "    fanin = fanin or size[0]\n",
    "    v = 1. / np.sqrt(fanin)\n",
    "    return torch.Tensor(size).uniform_(-v, v)\n",
    "\n",
    "\n",
    "# classes\n",
    "class Experience(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.mem = []\n",
    "        self.pos = 0\n",
    "    \n",
    "    def push(self, o, a, r, o_next):\n",
    "        if len(self.mem) < self.capacity:\n",
    "            self.mem.append(None)\n",
    "        self.mem[self.pos] = Transition(o, a, r, o_next)\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, size):\n",
    "        return random.sample(self.mem, min(size, len(self.mem)))\n",
    "        #return self.mem[:1]\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fcS = nn.Linear(N_STATES, 400)\n",
    "        #nn.init.kaiming_normal(self.fcS.weight)\n",
    "        #nn.init.uniform(self.fcS.weight, uf_lb, uf_ub)\n",
    "        self.fcS.weight.data = fanin_init(self.fcS.weight.data.size())\n",
    "        self.bnS = nn.BatchNorm1d(400)\n",
    "        \n",
    "        self.fcA = nn.Linear(N_ACTIONS, 400)\n",
    "        #nn.init.kaiming_normal(self.fcA.weight)\n",
    "        #nn.init.uniform(self.fcA.weight, uf_lb, uf_ub)\n",
    "        self.fcA.weight.data = fanin_init(self.fcA.weight.data.size())\n",
    "        self.bnA = nn.BatchNorm1d(400)\n",
    "        \n",
    "        self.fc1 = nn.Linear(400, 300)\n",
    "        #nn.init.kaiming_normal(self.fc1.weight)\n",
    "        #nn.init.uniform(self.fc1.weight, uf_lb, uf_ub)\n",
    "        self.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "        self.bn1 = nn.BatchNorm1d(300)\n",
    "        \n",
    "        self.fc2 = nn.Linear(300, 1)\n",
    "        #nn.init.kaiming_normal(self.fc2.weight)\n",
    "        nn.init.uniform(self.fc2.weight, uf_lb, uf_ub)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "#         s = F.relu(self.bnS(self.fcS(x)))\n",
    "#         a = F.relu(self.bnA(self.fcA(y)))\n",
    "#         o = F.relu(self.bn1(self.fc1(s+a)))\n",
    "#         o = self.fc2(o)\n",
    "               \n",
    "        s = (self.fcS(x))\n",
    "        a = (self.fcA(y))\n",
    "        o = F.relu(s+a)\n",
    "        o = (self.fc1(o))\n",
    "        o = F.relu(o)\n",
    "        o = (self.fc2(o))\n",
    "        \n",
    "        return o\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES/N_UAVS, 400)\n",
    "        #nn.init.kaiming_normal(self.fc1.weight)\n",
    "        #nn.init.uniform(self.fc1.weight, uf_lb, uf_ub)\n",
    "        self.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "        self.bn1 = nn.BatchNorm1d(400)\n",
    "        \n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        #nn.init.kaiming_normal(self.fc2.weight)\n",
    "        #nn.init.uniform(self.fc2.weight, uf_lb, uf_ub)\n",
    "        self.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "        self.bn2 = nn.BatchNorm1d(300)\n",
    "        \n",
    "        self.fc3 = nn.Linear(300, N_ACTIONS/N_UAVS)\n",
    "        #nn.init.kaiming_normal(self.fc3.weight)\n",
    "        nn.init.uniform(self.fc3.weight, uf_lb, uf_ub)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.fc1(x)))\n",
    "#         x = F.relu(self.bn2(self.fc2(x)))\n",
    "#         x = self.fc3(x)\n",
    "        \n",
    "        x = (self.fc1(x))\n",
    "        x = F.relu(x)\n",
    "        x = (self.fc2(x))\n",
    "        x = F.relu(x)\n",
    "        x = (self.fc3(x))\n",
    "        x = F.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [reference] https://github.com/matthiasplappert/keras-rl/blob/master/rl/random.py\n",
    "\n",
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "\n",
    "\n",
    "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_to_v(a, low, high):\n",
    "    return (low+high)/2 + a*(high-low)/2\n",
    "\n",
    "def choose_action(state, actor, rand_proc=None):\n",
    "    global epsilon\n",
    "    a = actor(Variable(Tensor(state).unsqueeze(0))).data.cpu().numpy()[0].astype('float64')\n",
    "    if rand_proc is not None:\n",
    "        a += max(epsilon, 0)*rand_proc.sample()\n",
    "        a = np.clip(a, -1., 1.)\n",
    "        epsilon -= EPSILON_DECAY\n",
    "    #print epsilon\n",
    "    return a\n",
    "\n",
    "def update_actor_critic(target_actor, target_critic, \\\n",
    "                       actor, critic, exp, optim_actor, optim_critic):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sample minibatch\n",
    "    minibatch = Transition(*zip(*exp.sample(BATCH_SIZE)))\n",
    "    bat_o = Variable(Tensor(minibatch.state))\n",
    "    bat_a = Variable(Tensor(minibatch.action))\n",
    "    bat_r = Variable(Tensor(minibatch.reward)).unsqueeze(1)\n",
    "    bat_o_ = Variable(Tensor(minibatch.next_state))\n",
    "    \n",
    "    bat_a0_ = target_actor(bat_o_[:,:N_STATES/N_UAVS])\n",
    "    #bat_a1_ = target_actor(bat_o_[:,N_STATES/N_UAVS:-N_STATES/N_UAVS])\n",
    "    #bat_a2_ = target_actor(bat_o_[:,-N_STATES/N_UAVS:])\n",
    "    #bat_a_o_ = torch.cat([bat_a0_, bat_a1_, bat_a2_], dim=1)\n",
    "    bat_a_o_ = bat_a0_\n",
    "\n",
    "    Gt = bat_r + GAMMA * target_critic(bat_o_, bat_a_o_)\n",
    "    Gt.detach_()\n",
    "    eval_o = critic(bat_o, bat_a)\n",
    "    criterion = nn.MSELoss()\n",
    "    if use_cuda:\n",
    "        criterion.cuda()\n",
    "    loss = criterion(eval_o, Gt)\n",
    "    #optimizer = optim.Adam(critic.parameters(), lr=LR_critic)\n",
    "    optim_critic.zero_grad()\n",
    "    loss.backward()\n",
    "    optim_critic.step()\n",
    "    \n",
    "    # update actor\n",
    "    bat_a0 = actor(bat_o[:,:N_STATES/N_UAVS])\n",
    "    #bat_a1 = actor(bat_o[:,N_STATES/N_UAVS:-N_STATES/N_UAVS])\n",
    "    #bat_a2 = actor(bat_o[:,-N_STATES/N_UAVS:])\n",
    "    #bat_a_o = torch.cat([bat_a0, bat_a1, bat_a2], dim=1)\n",
    "    bat_a_o = bat_a0\n",
    "    \n",
    "    obj = torch.mean(critic(bat_o, bat_a_o))\n",
    "    #optimizer = optim.Adam(actor.parameters(), lr=-LR_actor)\n",
    "    optim_actor.zero_grad()\n",
    "    obj.backward()\n",
    "    optim_actor.step()    \n",
    "\n",
    "def update_target(target_actor, target_critic, \\\n",
    "                         actor, critic):\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    target_critic.load_state_dict(critic.state_dict())\n",
    "\n",
    "def soft_update(target, behavior, tau):\n",
    "    for key in target.state_dict().keys():\n",
    "        target.state_dict()[key].copy_(tau * behavior.state_dict()[key] + (1-tau) * target.state_dict()[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_vec_r = []\n",
    "n_vec_avg_cost = []\n",
    "n_vec_total_cost = []\n",
    "n_vec_target_update = []\n",
    "n_vec_experience_refresh = []\n",
    "n_vec_training_time = []\n",
    "for n in xrange(N):    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    target_actor = Actor()\n",
    "    target_critic = Critic()\n",
    "    target_actor.eval()\n",
    "    target_critic.eval()\n",
    "    \n",
    "    actor = Actor()\n",
    "    critic = Critic()\n",
    "    if use_cuda:\n",
    "        target_actor.cuda()\n",
    "        target_critic.cuda()\n",
    "        actor.cuda()\n",
    "        critic.cuda()\n",
    "    exp = Experience(EXPERIENCE_CAPACITY)\n",
    "    optim_critic = optim.Adam(critic.parameters(), lr=LR_critic)\n",
    "    optim_actor = optim.Adam(actor.parameters(), lr=-LR_actor)\n",
    "\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    target_critic.load_state_dict(critic.state_dict())\n",
    "    \n",
    "    random_process = OrnsteinUhlenbeckProcess(\\\n",
    "            size=N_ACTIONS/N_UAVS, theta=.15, mu=0, sigma=.2)\n",
    "    epsilon = EPSILON\n",
    "    \n",
    "    vec_r = []\n",
    "    vec_avg_cost = []\n",
    "    vec_total_cost = []\n",
    "    vec_target_update = []\n",
    "    vec_experience_refresh = []\n",
    "    update_counter = 0\n",
    "    for epi in xrange(MAX_EPI):\n",
    "        if epi%(MAX_EPI/10)==0:\n",
    "            print 'n:{}, epi:{}'.format(n, epi)\n",
    "                    \n",
    "        random_process.reset_states()\n",
    "        \n",
    "        o = env.reset()\n",
    "        acc_r = 0\n",
    "        \n",
    "        local_r = []\n",
    "        \n",
    "        avg_cost = np.zeros([4])\n",
    "        total_cost = 0\n",
    "    \n",
    "        counter = 0\n",
    "        #for t in xrange(MAX_STEP):    \n",
    "        while True:\n",
    "            counter += 1\n",
    "            \n",
    "            if RECORD:\n",
    "                env.render()\n",
    "            \n",
    "            #actor.eval()\n",
    "            \n",
    "            a0 = choose_action(o[:N_STATES/N_UAVS], actor)\n",
    "#             a0 = choose_action(o[:N_STATES/N_UAVS], actor, random_process)\n",
    "            #a1 = choose_action(o[N_STATES/N_UAVS:-N_STATES/N_UAVS], actor)\n",
    "            #a2 = choose_action(o[-N_STATES/N_UAVS:], actor)\n",
    "            #a = np.hstack([a0, a1, a2])\n",
    "            a = a0\n",
    "            \n",
    "#             # ground truth\n",
    "#             if update_counter<1000:\n",
    "# #                 a = np.array([0.,3./5.])\n",
    "#                 a = np.array([0.,3.])\n",
    "            \n",
    "            o_, r, done, info = env.step(map_to_v(a, -V_MAX, V_MAX))\n",
    "#            o_, r, done, info = env.step(a)\n",
    "    \n",
    "            exp.push(o, a, r, o_)\n",
    "            \n",
    "#             cost = np.array(info['cost'])\n",
    "#             avg_cost += (cost-avg_cost)/(counter)\n",
    "            total_cost += r\n",
    "            \n",
    "            actor.train()\n",
    "            \n",
    "            update_actor_critic(target_actor, target_critic, \\\n",
    "                               actor, critic, exp, optim_actor, optim_critic)\n",
    "            update_counter += 1\n",
    "            \n",
    "            if update_counter % TARGET_UPDATE_FREQUENCY == 0:\n",
    "                vec_target_update.append(epi)\n",
    "                update_target(target_actor, target_critic, \\\n",
    "                             actor, critic)\n",
    "            if update_counter % EXPERIENCE_CAPACITY == 0:\n",
    "                vec_experience_refresh.append(epi)\n",
    "            \n",
    "            local_r.append(r)\n",
    "            acc_r += r\n",
    "            o = o_\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        vec_r.append(acc_r)\n",
    "        vec_avg_cost.append(avg_cost)\n",
    "        vec_total_cost.append(total_cost)\n",
    "        \n",
    "    n_vec_r.append(vec_r)\n",
    "    n_vec_avg_cost.append(vec_avg_cost)\n",
    "    n_vec_total_cost.append(vec_total_cost)\n",
    "    n_vec_target_update.append(vec_target_update)\n",
    "    n_vec_experience_refresh.append(vec_experience_refresh)\n",
    "    n_vec_training_time.append((time.time() - start_time)/60)\n",
    "    \n",
    "    torch.save(actor.state_dict(), '{}/actor{}.pt'.format(exp_name, n))\n",
    "    \n",
    "    print \"--- {} minutes ---\".format((time.time() - start_time)/60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_avg_1d(vec, title=None, xlabel=None, ylabel=None, save=False, folder='.',\\\n",
    "                ylim=None, begin=0, marker='', target=None, exp=None):\n",
    "    record = np.array(vec)\n",
    "    if len(record.shape) is not 1:\n",
    "        print 'vec should be 1D array [e0, e1, ...]'\n",
    "        return\n",
    "    if ylim is not None:\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim(ylim)\n",
    "    mu = record.mean(axis=0)\n",
    "    plt.plot(np.array(range(record.shape[0]))+begin, record, marker)\n",
    "    plt.plot(np.array(range(record.shape[0]))+begin, mu*np.ones(record.shape[0]), color='red')\n",
    "    patches = []\n",
    "    if target is not None and len(target)>0:\n",
    "        target = np.array(target)\n",
    "        target_color = 'b'\n",
    "        target_patch = mpatches.Patch(color=target_color, label='update target')\n",
    "        patches.append(target_patch)\n",
    "        for t in target:\n",
    "            plt.axvline(t, ls='dashed', c=target_color)\n",
    "    if exp is not None and len(exp)>0:\n",
    "        exp = np.array(exp)\n",
    "        exp_color = 'r'\n",
    "        exp_patch = mpatches.Patch(color=exp_color, label='exp refresh')\n",
    "        patches.append(exp_patch)\n",
    "        for e in exp:\n",
    "            plt.axvline(e, ls='dashed', c=exp_color)\n",
    "    if len(patches)>0:\n",
    "        plt.legend(handles=patches)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel, rotation=45)\n",
    "    if save:\n",
    "        plt.savefig('{}/{}.png'.format(folder, title))      \n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_2d(vec, title=None, xlabel=None, ylabel=None, save=False, folder='.',\\\n",
    "                ylim=None, begin=0):\n",
    "    record = np.array(vec)\n",
    "    if len(record.shape) is not 2:\n",
    "        print 'vec should be 2D array [[seq0], [seq1], ...]'\n",
    "        return\n",
    "    if ylim is not None:\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim(ylim)\n",
    "    mu = record.mean(axis=0)\n",
    "    sigma = record.std(axis=0)\n",
    "    lower_bound = mu-sigma\n",
    "    upper_bound = mu+sigma\n",
    "    plt.plot(np.array(range(mu.shape[0]))+begin, mu, color='red')\n",
    "    plt.fill_between(np.array(range(mu.shape[0]))+begin, lower_bound, upper_bound, facecolor='blue', alpha=0.5)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel, rotation=45)\n",
    "    if save:\n",
    "        plt.savefig('{}/{}.png'.format(folder, title))\n",
    "    plt.show()\n",
    "\n",
    "# data\n",
    "n_vec_avg_cost = np.array(n_vec_avg_cost)\n",
    "n_vec_total_cost = np.array(n_vec_total_cost)\n",
    "n_vec_target_update = np.array(n_vec_target_update)\n",
    "n_vec_experience_refresh = np.array(n_vec_experience_refresh)\n",
    "\n",
    "\n",
    "#cost = gym_foa.envs.FoaEnv.Cost(*np.rollaxis(n_vec_avg_cost,2))\n",
    "#avg_cost = cost.collision[0]+cost.goal[0]+cost.formation[0]+cost.v_pref[0]\n",
    "\n",
    "# param\n",
    "save = True\n",
    "marker = '.'\n",
    "\n",
    "target = np.array([10,20,30])\n",
    "experience = np.array([15,25])\n",
    "\n",
    "plot_avg_2d(n_vec_total_cost, title='total cost', ylim=[-8000,1000], save=save, folder=exp_name)\n",
    "for i in xrange(n_vec_avg_cost.shape[0]):\n",
    "    plot_avg_1d(n_vec_total_cost[i], title='total cost of {} \\n training time: {} minutes'.format(i, n_vec_training_time[i]),\\\n",
    "                ylim=[-8000,1000], save=save, folder=exp_name)\n",
    "                #target=n_vec_target_update[i], )\n",
    "                #exp=n_vec_experience_refresh[i])\n",
    "\n",
    "# plot_avg_2d(n_vec_total_cost, title='total cost', save=save, folder=exp_name)\n",
    "# for i in xrange(n_vec_avg_cost.shape[0]):\n",
    "#     plot_avg_1d(n_vec_total_cost[i], title='total cost of {} \\n training time: {} minutes'.format(i, n_vec_training_time[i]),\\\n",
    "#                 save=save, folder=exp_name)\n",
    "#                 #target=n_vec_target_update[i], )\n",
    "#                 #exp=n_vec_experience_refresh[i])\n",
    "\n",
    "# marker = ''\n",
    "# int0 = slice(0,500)\n",
    "# plot_avg_1d(n_vec_total_cost[0][int0], title='total cost: first drop', ylim=[-8000,1000], begin=int0.start, save=save, marker=marker)\n",
    "#plot_avg_1d(cost.v_pref[0][int0], title='v_pref: first drop', begin=int0.start, save=save, marker=marker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(actor.state_dict(), 'actor_3w.param')\n",
    "#torch.save(critic.state_dict(), 'critic.param')\n",
    "\n",
    "#from gym import wrappers\n",
    "\n",
    "#env = wrappers.Monitor(env, 'exp', force=True)\n",
    "\n",
    "\n",
    "actor = Actor()\n",
    "actor.cuda()\n",
    "#actor.eval()\n",
    "actor.train()\n",
    "actor.load_state_dict(torch.load('actor0.pt'))\n",
    "print actor.state_dict()\n",
    "\n",
    "s = np.ones(N_STATES/N_UAVS)\n",
    "s = Variable(Tensor(s)).unsqueeze(0)\n",
    "#print s\n",
    "# for _ in xrange(10):\n",
    "#     print actor(s)\n",
    "#     print actor.state_dict()['bn1.running_mean'][:10]\n",
    "\n",
    "\n",
    "\n",
    "#actor.eval()\n",
    "#actor.cuda()\n",
    "\n",
    "# start_time = time.time()\n",
    "# counter = 0\n",
    "# for n in xrange(10):\n",
    "#     o = env.reset()\n",
    "#     for t in xrange(MAX_STEP):\n",
    "#         counter += 1\n",
    "# #        print 'n:{}, t:{}'.format(n, t)\n",
    "# #         env.render()\n",
    "#         #a0 = choose_action(o[:N_STATES/N_UAVS], actor)\n",
    "        \n",
    "        \n",
    "#         a0 = actor(Variable(torch.FloatTensor(o[:N_STATES/N_UAVS]).unsqueeze(0))).data.cpu().numpy()[0].astype('float64')\n",
    "        \n",
    "        \n",
    "#         #a1 = choose_action(o[N_STATES/N_UAVS:-N_STATES/N_UAVS], actor)\n",
    "#         #a2 = choose_action(o[-N_STATES/N_UAVS:], actor)\n",
    "#         #a = np.hstack([a0, a1, a2])\n",
    "        \n",
    "# #        print a0\n",
    "        \n",
    "#         o_, r, done, info = env.step(a0)\n",
    "    \n",
    "#         o = o_\n",
    "#         if done:\n",
    "#             break\n",
    "# (time.time() - start_time)/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "name = 'capa_7.5k_epi_2w_x5'\n",
    "\n",
    "# Saving the objects:\n",
    "with open('{}_total_cost.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_total_cost, f)\n",
    "\n",
    "with open('{}_target_update.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_target_update, f)\n",
    "\n",
    "with open('{}_experience_refresh.pickle'.format(name), 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(n_vec_experience_refresh, f)\n",
    "    \n",
    "    \n",
    "## Getting back the objects:\n",
    "#with open('objs.pickle') as f:  # Python 3: open(..., 'rb')\n",
    "#    k = pickle.load(f)\n",
    "    \n",
    "#print cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
